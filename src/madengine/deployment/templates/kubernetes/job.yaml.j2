apiVersion: batch/v1
kind: Job
metadata:
  name: {{ job_name }}
  namespace: {{ namespace }}
  labels:
    app: madengine
    model: {{ model_name }}
    madengine-job: "true"
spec:
  completions: {{ completions }}
  parallelism: {{ parallelism }}
  {% if completion_mode %}
  completionMode: {{ completion_mode }}
  {% endif %}
  backoffLimit: {{ backoff_limit }}
  template:
    metadata:
      labels:
        app: madengine
        job-name: {{ job_name }}
        model: {{ model_name }}
    spec:
      {% if subdomain %}
      subdomain: {{ subdomain }}  # Required for DNS in headless service
      {% endif %}
      restartPolicy: Never
      terminationGracePeriodSeconds: 60
      {% if subdomain %}
      subdomain: {{ subdomain }}
      {% endif %}
      {% if node_selector %}
      nodeSelector:
        {% for key, value in node_selector.items() %}
        {{ key }}: "{{ value }}"
        {% endfor %}
      {% endif %}
      {% if host_ipc %}
      hostIPC: true
      {% endif %}
      
      # Init container extracts madengine scripts from package
      initContainers:
      - name: extract-scripts
        image: {{ image }}
        command: ["/bin/bash", "-c"]
        args:
          - |
            set -e
            echo "=== Extracting madengine scripts ==="
            
            # Extract common scripts from ConfigMap (since madengine not installed in container)
            {% if common_script_contents %}
            echo "Extracting common scripts from ConfigMap..."
            {% for script_path, script_content in common_script_contents.items() %}
            mkdir -p /workspace/{{ script_path | dirname }}
            cp /config/{{ script_path | replace("/", "-") }} /workspace/{{ script_path }}
            chmod +x /workspace/{{ script_path }} 2>/dev/null || true
            {% endfor %}
            echo "âœ“ Extracted {{ common_script_contents | length }} common script(s)"
            {% else %}
            echo "No common scripts to extract"
            {% endif %}
            
            # Copy K8s data provider script from ConfigMap if it exists
            if [ -f /config/data_provider.sh ]; then
                echo "Copying data_provider.sh to /workspace/data_provider.sh"
                cp /config/data_provider.sh /workspace/data_provider.sh
                chmod +x /workspace/data_provider.sh
                echo "âœ“ Copied K8s data provider script"
            fi
            
            # Extract model scripts directory (all .sh, .py, and .json files)
            {% if model_scripts_contents %}
            echo "Extracting model scripts directory..."
            {% for script_path, _ in model_scripts_contents.items() %}
            {%   set config_key = script_path | replace("/", "-") %}
            {%   set script_dir = script_path | dirname %}
            mkdir -p /workspace/{{ script_dir }}
            if [ -f /config/{{ config_key }} ]; then
                cp /config/{{ config_key }} /workspace/{{ script_path }}
                # Only chmod executable files (.sh, .py), not config files (.json)
                {% if script_path.endswith('.sh') or script_path.endswith('.py') %}
                chmod +x /workspace/{{ script_path }}
                {% endif %}
                echo "  âœ“ {{ script_path }}"
            fi
            {% endfor %}
            echo "âœ“ Extracted {{ model_scripts_contents | length }} model script(s)"
            {% else %}
            echo "Warning: No model scripts configured"
            {% endif %}
            
            echo "âœ“ Script extraction complete"
        volumeMounts:
        - name: workspace
          mountPath: /workspace
        - name: config
          mountPath: /config
          readOnly: true
      
      # Main container runs benchmark
      containers:
      - name: {{ job_name }}
        image: {{ image }}
        imagePullPolicy: {{ image_pull_policy }}
        workingDir: /workspace
        command: ["/bin/bash", "-c"]
        args:
          - |
            set -e
            echo "==================================================================="
            echo "madengine Kubernetes Benchmark Job"
            echo "Model: {{ model_name }}"
            echo "Pod: $HOSTNAME"
            {% if launcher_type %}
            echo "Launcher: {{ launcher_type }}"
            {% endif %}
            echo "==================================================================="
            
            # Copy config files from ConfigMap to workspace
            cp /config/build_manifest.json /workspace/
            cp /config/credential.json /workspace/ 2>/dev/null || true
            cp /config/data.json /workspace/ 2>/dev/null || true
            
            # GPU Information
            if command -v rocm-smi &> /dev/null; then
                echo ""
                echo "=== AMD GPU Information ==="
                rocm-smi || true
            fi
            
            # Set GPU visibility for ROCm/CUDA
            # CRITICAL: Ray (vLLM, SGLang) requires ONLY ONE visibility variable
            # - AMD GPUs: Use ONLY HIP_VISIBLE_DEVICES
            # - NVIDIA GPUs: Use ONLY CUDA_VISIBLE_DEVICES
            # Setting both HIP_VISIBLE_DEVICES and CUDA_VISIBLE_DEVICES simultaneously
            # causes Ray error: "Inconsistent values found"
            {% if launcher_type == "vllm" or launcher_type == "sglang" %}
            # Ray-based launchers: Detect GPU vendor and set appropriate variable
            if command -v rocm-smi &> /dev/null || command -v rocminfo &> /dev/null; then
                # AMD GPU detected - use HIP_VISIBLE_DEVICES ONLY
                # CRITICAL: Unset RAY_EXPERIMENTAL_NOSET_HIP_VISIBLE_DEVICES which is set by rocm/vllm image
                # This variable tells Ray to ignore HIP_VISIBLE_DEVICES, causing conflicts
                unset RAY_EXPERIMENTAL_NOSET_HIP_VISIBLE_DEVICES
                export HIP_VISIBLE_DEVICES=${HIP_VISIBLE_DEVICES:-{{ gpu_visibility }}}
                unset ROCR_VISIBLE_DEVICES  # Unset to avoid Ray conflicts
                unset CUDA_VISIBLE_DEVICES  # Unset to avoid "Inconsistent values" error
                echo "ðŸ”§ GPU Config (AMD): HIP_VISIBLE_DEVICES=$HIP_VISIBLE_DEVICES"
            else
                # NVIDIA GPU - use CUDA_VISIBLE_DEVICES ONLY
                export CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-{{ gpu_visibility }}}
                unset HIP_VISIBLE_DEVICES   # Unset to avoid Ray conflicts
                unset ROCR_VISIBLE_DEVICES
                echo "ðŸ”§ GPU Config (NVIDIA): CUDA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES"
            fi
            {% else %}
            # Non-Ray launchers: Set both HIP and ROCR for broader compatibility
            export HIP_VISIBLE_DEVICES=${HIP_VISIBLE_DEVICES:-{{ gpu_visibility }}}
            export ROCR_VISIBLE_DEVICES=${ROCR_VISIBLE_DEVICES:-{{ gpu_visibility }}}
            export CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-{{ gpu_visibility }}}
            {% endif %}
            export MAD_SYSTEM_GPU_ARCHITECTURE={{ gpu_architecture }}
            
            # K8s environment
            export MAD_K8S_POD_NAME=$HOSTNAME
            export MAD_K8S_NAMESPACE={{ namespace }}
            export MAD_K8S_JOB=true
            export MAD_DEPLOYMENT_TYPE=kubernetes
            
            {% if launcher_type == "torchrun" or launcher_type == "deepspeed" or launcher_type == "megatron" %}
            # {{ launcher_type }} distributed environment (auto-configured from K8s)
            {% if nnodes > 1 %}
            # Multi-node {{ launcher_type }} (Indexed Job)
            export JOB_COMPLETION_INDEX=${JOB_COMPLETION_INDEX:-0}
            export POD_INDEX=$JOB_COMPLETION_INDEX
            {% else %}
            # Single-node {{ launcher_type }}
            export JOB_COMPLETION_INDEX=0
            {% endif %}
            {% endif %}
            
            # Data provider environment variables
            {% if data_config %}
            echo ""
            echo "=== Setting up data environment ==="
            export MAD_DATANAME="{{ data_config.data_name }}"
            {% for key, value in data_config.env_vars.items() %}
            export {{ key }}="{{ value }}"
            {% endfor %}
            echo "âœ“ Data environment configured for: {{ data_config.data_name }}"
            {% endif %}
            
            # Tools configuration environment variables
            {% if tools_config %}
            echo ""
            echo "=== Applying tools configuration ==="
            {% for tool in tools_config %}
            echo "Tool: {{ tool.name }}"
            {% if tool.env_vars %}
            {% for key, value in tool.env_vars.items() %}
            export {{ key }}="{{ value }}"
            {% endfor %}
            {% endif %}
            {% endfor %}
            echo "âœ“ Tools configuration applied"
            {% endif %}
            
            {% if launcher_command %}
            # Launcher-based execution with tools
            echo ""
            echo "=== Starting benchmark with {{ launcher_type }} ==="
            
            cd /workspace
            
            # Download data if data provider is configured
            {% if data_provider_script and data_config %}
            echo ""
            echo "=== Data Provider: {{ data_config.provider_type }} ==="
            echo "Data name: {{ data_config.data_name }}"
            echo "Source: {{ data_config.source_url }}"
            echo "Target: {{ data_config.datahome }}"
            
            # Use K8s data provider script (loaded from ConfigMap)
            if [ -f /workspace/data_provider.sh ]; then
                bash /workspace/data_provider.sh \
                  "{{ data_config.data_name }}" \
                  "{{ data_config.source_url }}" \
                  "{{ data_config.datahome }}"
                
                # Source metrics if available
                if [ -f /tmp/mad_metrics.env ]; then
                    source /tmp/mad_metrics.env
                    echo "âœ“ Data metrics: Duration=${MAD_DATA_DOWNLOAD_DURATION}s, Size=${MAD_DATA_SIZE}"
                fi
            else
                echo "Error: Data provider script not found at /workspace/data_provider.sh"
                exit 1
            fi
            {% endif %}
            
            # Run pre-scripts (like local execution)
            {% if pre_scripts %}
            echo ""
            echo "=== Running pre-scripts ==="
            {% for script in pre_scripts %}
            # Execute: {{ script.path }}
            if [ -f "{{ script.path }}" ]; then
                echo "Executing: {{ script.path }} {% if script.args %}{{ script.args }}{% endif %}"
                bash {{ script.path }} {% if script.args %}{{ script.args }}{% endif %} || echo "Warning: {{ script.path }} failed with exit code $?"
            else
                echo "Warning: Script not found: {{ script.path }}"
            fi
            {% endfor %}
            echo "âœ“ Pre-scripts completed"
            {% else %}
            echo "No pre-scripts configured"
            {% endif %}
            
            # Clear MIOpen cache to prevent "Duplicate ID" warnings
            echo ""
            echo "=== Clearing MIOpen cache ==="
            if [ -d "${MIOPEN_USER_DB_PATH:-/tmp/.miopen}" ]; then
                rm -rf "${MIOPEN_USER_DB_PATH:-/tmp/.miopen}"/*
                echo "âœ“ Cleared MIOpen cache directory"
            fi
            mkdir -p "${MIOPEN_USER_DB_PATH:-/tmp/.miopen}"
            
            # Create wrapper script for launcher
            echo ""
            echo "=== Running model benchmark with launcher ==="
            cat > /tmp/run_launcher.sh << 'LAUNCHER_EOF'
            #!/bin/bash
            {{ launcher_command | indent(12, first=False) }}
            LAUNCHER_EOF
            chmod +x /tmp/run_launcher.sh
            
            {% if tools_config and tools_config|length > 0 %}
            # Run with profiling tools
            {%   for tool in tools_config %}
            {%     if tool.cmd %}
            echo "Using profiling tool: {{ tool.name }}"
            {%     endif %}
            {%   endfor %}
            {% endif %}
            
            # Execute launcher with tool chain
            MODEL_START_TIME=$(date +%s.%N)
            {% if launcher_tool_chain and launcher_tool_chain != "bash /tmp/run_launcher.sh" %}
            {{ launcher_tool_chain }}
            {% else %}
            bash /tmp/run_launcher.sh
            {% endif %}
            MODEL_EXIT_CODE=$?
            MODEL_END_TIME=$(date +%s.%N)
            MODEL_DURATION=$(awk "BEGIN {printf \"%.6f\", $MODEL_END_TIME - $MODEL_START_TIME}")
            echo "test_duration: ${MODEL_DURATION}s"
            
            # Run post-scripts (like local execution)
            {% if post_scripts %}
            echo ""
            echo "=== Running post-scripts ==="
            {% for script in post_scripts %}
            # Execute: {{ script.path }}
            if [ -f "{{ script.path }}" ]; then
                echo "Executing: {{ script.path }} {% if script.args %}{{ script.args }}{% endif %}"
                bash {{ script.path }} {% if script.args %}{{ script.args }}{% endif %} || echo "Warning: {{ script.path }} failed with exit code $?"
            else
                echo "Warning: Script not found: {{ script.path }}"
            fi
            {% endfor %}
            echo "âœ“ Post-scripts completed"
            {% else %}
            echo "No post-scripts configured"
            {% endif %}
            
            # Copy artifacts to PVC shared storage (always enabled)
            echo ""
            echo "=== Copying artifacts to PVC storage ==="
            mkdir -p /results/${HOSTNAME}
            
            # Copy performance results
            if [ -f "perf.csv" ]; then
                cp perf.csv /results/${HOSTNAME}/perf.csv
                echo "âœ“ Copied perf.csv"
            fi
            
            # Copy environment details
            if ls *_env.csv 1> /dev/null 2>&1; then
                cp *_env.csv /results/${HOSTNAME}/
                echo "âœ“ Copied environment CSV files"
            fi
            
            # Copy profiling outputs (rocprof, rocprofv3)
            if ls results* 1> /dev/null 2>&1; then
                cp -r results* /results/${HOSTNAME}/ 2>/dev/null || true
                echo "âœ“ Copied profiling results"
            fi
            if ls *.db 1> /dev/null 2>&1; then
                cp *.db /results/${HOSTNAME}/ 2>/dev/null || true
                echo "âœ“ Copied profiling database files"
            fi
            # Copy rocprofv3 UUID directories
            for dir in */; do
                if [ -d "$dir" ] && [ -f "${dir}"*_results.db ] 2>/dev/null; then
                    cp -r "$dir" /results/${HOSTNAME}/
                    echo "âœ“ Copied rocprofv3 directory: $dir"
                fi
            done
            
            # Copy tool-specific outputs
            if ls gpu_info_*.csv 1> /dev/null 2>&1; then
                cp gpu_info_*.csv /results/${HOSTNAME}/
                echo "âœ“ Copied GPU profiler outputs"
            fi
            if ls *_trace_output.csv 1> /dev/null 2>&1; then
                cp *_trace_output.csv /results/${HOSTNAME}/
                echo "âœ“ Copied library trace outputs"
            fi
            if ls prof.csv 1> /dev/null 2>&1; then
                cp prof.csv /results/${HOSTNAME}/
                echo "âœ“ Copied prof.csv"
            fi
            
            echo "âœ“ All artifacts copied to PVC: /results/${HOSTNAME}/"
            
            echo "=== Benchmark job completed with exit code $MODEL_EXIT_CODE ==="
            exit $MODEL_EXIT_CODE
            {% else %}
            # Direct script execution
            cd /workspace
            
            # Download data if data provider is configured
            {% if data_provider_script and data_config %}
            echo ""
            echo "=== Data Provider: {{ data_config.provider_type }} ==="
            echo "Data name: {{ data_config.data_name }}"
            echo "Source: {{ data_config.source_url }}"
            echo "Target: {{ data_config.datahome }}"
            
            # Use K8s data provider script (loaded from ConfigMap)
            if [ -f /workspace/data_provider.sh ]; then
                bash /workspace/data_provider.sh \
                  "{{ data_config.data_name }}" \
                  "{{ data_config.source_url }}" \
                  "{{ data_config.datahome }}"
                
                # Source metrics if available
                if [ -f /tmp/mad_metrics.env ]; then
                    source /tmp/mad_metrics.env
                    echo "âœ“ Data metrics: Duration=${MAD_DATA_DOWNLOAD_DURATION}s, Size=${MAD_DATA_SIZE}"
                fi
            else
                echo "Error: Data provider script not found at /workspace/data_provider.sh"
                exit 1
            fi
            {% endif %}
            
            # Run pre-scripts (like local execution)
            {% if pre_scripts %}
            echo ""
            echo "=== Running pre-scripts ==="
            {% for script in pre_scripts %}
            # Execute: {{ script.path }}
            if [ -f "{{ script.path }}" ]; then
                echo "Executing: {{ script.path }} {% if script.args %}{{ script.args }}{% endif %}"
                bash {{ script.path }} {% if script.args %}{{ script.args }}{% endif %} || echo "Warning: {{ script.path }} failed with exit code $?"
            else
                echo "Warning: Script not found: {{ script.path }}"
            fi
            {% endfor %}
            echo "âœ“ Pre-scripts completed"
            {% else %}
            echo "No pre-scripts configured"
            {% endif %}
            
            # Clear MIOpen cache to prevent "Duplicate ID" warnings
            echo ""
            echo "=== Clearing MIOpen cache ==="
            if [ -d "${MIOPEN_USER_DB_PATH:-/tmp/.miopen}" ]; then
                rm -rf "${MIOPEN_USER_DB_PATH:-/tmp/.miopen}"/*
                echo "âœ“ Cleared MIOpen cache directory"
            fi
            mkdir -p "${MIOPEN_USER_DB_PATH:-/tmp/.miopen}"
            
            # Run main model script
            echo ""
            echo "=== Running model benchmark script ==="
            if [ -f "{{ model_script }}" ]; then
                {% if tools_config and tools_config|length > 0 %}
                # Run with profiling tools
                {%   for tool in tools_config %}
                {%     if tool.cmd %}
                echo "Using profiling tool: {{ tool.name }}"
                {%     endif %}
                {%   endfor %}
                {% endif %}
                
                # Execute script with tool chain
                MODEL_START_TIME=$(date +%s.%N)
                {% if direct_script_tool_chain and direct_script_tool_chain != "bash " ~ model_script %}
                {{ direct_script_tool_chain }}
                {% else %}
                bash {{ model_script }}
                {% endif %}
                MODEL_EXIT_CODE=$?
                MODEL_END_TIME=$(date +%s.%N)
                MODEL_DURATION=$(awk "BEGIN {printf \"%.6f\", $MODEL_END_TIME - $MODEL_START_TIME}")
                echo "test_duration: ${MODEL_DURATION}s"
            else
                echo "ERROR: Script not found: {{ model_script }}"
                echo "Available files in /workspace:"
                ls -la /workspace/
                echo ""
                echo "Available files in /workspace/scripts:"
                ls -la /workspace/scripts/ 2>/dev/null || echo "scripts/ directory not found"
                exit 1
            fi
            
            # Run post-scripts (like local execution)
            {% if post_scripts %}
            echo ""
            echo "=== Running post-scripts ==="
            {% for script in post_scripts %}
            # Execute: {{ script.path }}
            if [ -f "{{ script.path }}" ]; then
                echo "Executing: {{ script.path }} {% if script.args %}{{ script.args }}{% endif %}"
                bash {{ script.path }} {% if script.args %}{{ script.args }}{% endif %} || echo "Warning: {{ script.path }} failed with exit code $?"
            else
                echo "Warning: Script not found: {{ script.path }}"
            fi
            {% endfor %}
            echo "âœ“ Post-scripts completed"
            {% else %}
            echo "No post-scripts configured"
            {% endif %}
            
            # Copy artifacts to PVC shared storage (always enabled)
            echo ""
            echo "=== Copying artifacts to PVC storage ==="
            mkdir -p /results/${HOSTNAME}
            
            # Copy performance results
            if [ -f "perf.csv" ]; then
                cp perf.csv /results/${HOSTNAME}/perf.csv
                echo "âœ“ Copied perf.csv"
            fi
            
            # Copy environment details
            if ls *_env.csv 1> /dev/null 2>&1; then
                cp *_env.csv /results/${HOSTNAME}/
                echo "âœ“ Copied environment CSV files"
            fi
            
            # Copy profiling outputs (rocprof, rocprofv3)
            if ls results* 1> /dev/null 2>&1; then
                cp -r results* /results/${HOSTNAME}/ 2>/dev/null || true
                echo "âœ“ Copied profiling results"
            fi
            if ls *.db 1> /dev/null 2>&1; then
                cp *.db /results/${HOSTNAME}/ 2>/dev/null || true
                echo "âœ“ Copied profiling database files"
            fi
            # Copy rocprofv3 UUID directories
            for dir in */; do
                if [ -d "$dir" ] && [ -f "${dir}"*_results.db ] 2>/dev/null; then
                    cp -r "$dir" /results/${HOSTNAME}/
                    echo "âœ“ Copied rocprofv3 directory: $dir"
                fi
            done
            
            # Copy tool-specific outputs
            if ls -d *_output 1> /dev/null 2>&1; then
                cp -r *_output /results/${HOSTNAME}/ 2>/dev/null || true
                echo "âœ“ Copied tool output directories"
            fi
            
            # Copy GPU profiler outputs
            if ls gpu_info_*.csv 1> /dev/null 2>&1; then
                cp gpu_info_*.csv /results/${HOSTNAME}/
                echo "âœ“ Copied GPU profiler outputs"
            fi
            
            # Copy library trace outputs
            if ls *_trace_output.csv 1> /dev/null 2>&1; then
                cp *_trace_output.csv /results/${HOSTNAME}/
                echo "âœ“ Copied library trace outputs"
            fi
            if [ -f "library_trace.csv" ]; then
                cp library_trace.csv /results/${HOSTNAME}/library_trace.csv
                echo "âœ“ Copied library_trace.csv"
            fi
            
            # Copy tracing outputs
            if ls trace.* 1> /dev/null 2>&1; then
                cp trace.* /results/${HOSTNAME}/ 2>/dev/null || true
                echo "âœ“ Copied tracing files"
            fi
            
            echo "âœ“ All artifacts copied to PVC: /results/${HOSTNAME}/"
            
            echo ""
            echo "=== Benchmark job completed with exit code ${MODEL_EXIT_CODE:-0} ==="
            exit ${MODEL_EXIT_CODE:-0}
            {% endif %}
        
        resources:
          requests:
            {{ gpu_resource_name }}: "{{ gpu_count }}"
            memory: "{{ memory }}"
            cpu: "{{ cpu }}"
          limits:
            {{ gpu_resource_name }}: "{{ gpu_count }}"
            memory: "{{ memory_limit }}"
            cpu: "{{ cpu_limit }}"
        
        env:
        {% for key, value in env_vars.items() %}
        - name: {{ key }}
          value: "{{ value }}"
        {% endfor %}
        
        volumeMounts:
        - name: workspace
          mountPath: /workspace
        - name: config
          mountPath: /config
          readOnly: true
        - name: shm
          mountPath: /dev/shm
        - name: results
          mountPath: /results
        {% if data_pvc %}
        - name: data
          mountPath: /data
          readOnly: false  # Must be writable for data provider downloads
        {% endif %}
        
        securityContext:
          capabilities:
            add:
            - SYS_PTRACE
          seccompProfile:
            type: Unconfined
      
      {% if tolerations %}
      tolerations:
      {% for toleration in tolerations %}
      - key: {{ toleration.key }}
        {% if toleration.operator %}
        operator: {{ toleration.operator }}
        {% endif %}
        {% if toleration.value %}
        value: "{{ toleration.value }}"
        {% endif %}
        {% if toleration.effect %}
        effect: {{ toleration.effect }}
        {% endif %}
      {% endfor %}
      {% endif %}
      
      volumes:
      - name: workspace
        emptyDir: {}
      - name: config
        configMap:
          name: {{ configmap_name }}
      - name: shm
        emptyDir:
          medium: Memory
          sizeLimit: 16Gi  # Increased for Ray/vLLM (should be >30% of RAM, recommended 16Gi+)
      - name: results
        persistentVolumeClaim:
          claimName: {{ results_pvc }}
      {% if data_pvc %}
      - name: data
        persistentVolumeClaim:
          claimName: {{ data_pvc }}
      {% endif %}

