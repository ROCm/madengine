# Production environment configuration
# Extends default.yaml with production-specific settings

# General configuration
environment: "prod"

# Workspace configuration
workspace:
  path: "/opt/madengine/workspace"
  owner: "madengine"
  group: "madengine"

# Execution configuration
execution:
  timeout: 10800  # 3 hours for production
  keep_alive: false  # Don't keep containers alive in prod
  live_output: false  # Reduce output in prod
  output_file: "prod_perf.csv"
  results_file: "prod_execution_results.json"
  generate_sys_env_details: true
  async_timeout: 21600  # 6 hours
  poll_interval: 60  # Less frequent polling

# Data configuration
data_config:
  file: "prod_data.json"
  force_mirror_local: false
  required: true

# Credentials configuration
credentials:
  file: "prod_credential.json"
  required: true

# Docker registry configuration
docker_registry:
  login_required: true
  username: "prod-service-account"
  password: ""  # Should be set via secret

# Python configuration
python_dependencies:
  - jinja2
  - pyyaml
  - requests

# Installation configuration
install_dependencies: false  # Pre-installed in prod images

# Post-execution configuration
post_execution:
  cleanup: true  # Clean up in prod
  collect_logs: true

# Logging configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

logs:
  local_path: "/var/log/madengine"

# Ansible configuration
ansible:
  target_hosts: "prod_gpu_nodes"
  become: true

# Kubernetes configuration
k8s:
  namespace: "madengine-prod"
  
  # ConfigMap configuration
  configmap:
    name: "madengine-prod-config"
  
  # Job configuration
  job:
    name: "madengine-prod-execution"
    parallelism: 2  # Higher parallelism in prod
    completions: 2
    backoff_limit: 5  # More retries in prod
    active_deadline_seconds: 21600  # 6 hours
    restart_policy: "Never"
  
  # Container configuration
  container:
    image: "madengine/distributed-runner:stable"
    image_pull_policy: "IfNotPresent"
    security_context:
      run_as_user: 1001
      run_as_group: 1001
      privileged: false
    health_checks:
      liveness:
        initial_delay: 60
        period: 120
        timeout: 30
        failure_threshold: 5
      readiness:
        initial_delay: 30
        period: 30
        timeout: 10
  
  # Service configuration
  service:
    name: "madengine-prod-service"
    type: "ClusterIP"
    ports:
      - name: "http"
        port: 8080
        target_port: 8080
        protocol: "TCP"
      - name: "metrics"
        port: 9090
        target_port: 9090
        protocol: "TCP"
  
  # Volume configuration
  volumes:
    shared_storage:
      type: "pvc"
      claim_name: "madengine-prod-results"
    data_storage:
      type: "pvc"
      claim_name: "madengine-prod-data"
  
  # Node selector
  node_selector:
    environment: "prod"
    accelerator: "gpu"
    instance-type: "high-performance"
  
  # Tolerations for GPU nodes
  tolerations:
    - key: "nvidia.com/gpu"
      operator: "Exists"
      effect: "NoSchedule"
    - key: "prod-workload"
      operator: "Equal"
      value: "true"
      effect: "NoSchedule"
  
  # Service account for prod
  service_account: "madengine-prod-sa"
  
  # Image pull secrets
  image_pull_secrets:
    - "prod-registry-secret"
  
  # Affinity for better pod distribution
  affinity:
    pod_anti_affinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: "app.kubernetes.io/name"
                  operator: In
                  values:
                    - "madengine"
            topologyKey: "kubernetes.io/hostname"

# Resource configuration
resources:
  memory_limit: "8Gi"  # Higher limits for prod
  memory_request: "4Gi"
  cpu_limit: "4"
  cpu_request: "2"
  gpu_limit: "2"

# GPU vendor specific configuration
nvidia:
  visible_devices: "all"
  driver_capabilities: "compute,utility"

amd:
  visible_devices: "all"
  enable_pre_vega: "1"
