# Default configuration for MADEngine distributed execution
# This file contains the base configuration that can be overridden by environment-specific files

# General configuration
environment: "default"
manifest_file: "build_manifest.json"

# Workspace configuration
workspace:
  path: "/tmp/madengine_distributed"
  owner: "root"
  group: "root"

# Execution configuration
execution:
  timeout: 7200  # 2 hours
  keep_alive: false
  live_output: true
  output_file: "perf.csv"
  results_file: "execution_results.json"
  generate_sys_env_details: true
  async_timeout: 14400  # 4 hours
  poll_interval: 30
  additional_context: null
  additional_context_file: null

# Data configuration
data_config:
  file: "data.json"
  force_mirror_local: false
  required: false

# Credentials configuration
credentials:
  file: "credential.json"
  required: false

# Docker registry configuration
docker_registry:
  login_required: false
  username: ""
  password: ""

# Python configuration
python_path: "/usr/local/lib/python3.8/site-packages"
python_dependencies:
  - jinja2
  - pyyaml
  - requests

# Installation configuration
install_dependencies: false

# Post-execution configuration
post_execution:
  cleanup: false
  collect_logs: true

# Logging configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  
logs:
  local_path: "./logs"

# Ansible configuration
ansible:
  target_hosts: "gpu_nodes"
  become: true

# Kubernetes configuration
k8s:
  namespace: "madengine"
  
  # ConfigMap configuration
  configmap:
    name: "madengine-config"
  
  # Job configuration
  job:
    name: "madengine-execution"
    parallelism: 1
    completions: 1
    backoff_limit: 3
    active_deadline_seconds: 14400  # 4 hours
    restart_policy: "Never"
  
  # Container configuration
  container:
    image: "madengine/distributed-runner:latest"
    image_pull_policy: "IfNotPresent"
    security_context:
      run_as_user: 0
      run_as_group: 0
      privileged: false
    health_checks:
      liveness:
        initial_delay: 30
        period: 60
        timeout: 10
        failure_threshold: 3
      readiness:
        initial_delay: 5
        period: 10
        timeout: 5
  
  # Service configuration
  service:
    name: "madengine-service"
    type: "ClusterIP"
    ports:
      - name: "http"
        port: 8080
        target_port: 8080
        protocol: "TCP"
      - name: "metrics"
        port: 9090
        target_port: 9090
        protocol: "TCP"
  
  # Volume configuration
  volumes:
    shared_storage:
      type: "hostPath"
      path: "/tmp/madengine-results"
      hostPath_type: "DirectoryOrCreate"
  
  # Node selector
  node_selector:
    accelerator: "gpu"
  
  # Tolerations for GPU nodes
  tolerations:
    - key: "nvidia.com/gpu"
      operator: "Exists"
      effect: "NoSchedule"

# Resource configuration
resources:
  memory_limit: "4Gi"
  memory_request: "2Gi"
  cpu_limit: "2"
  cpu_request: "1"
  gpu_limit: "1"

# GPU vendor specific configuration
nvidia:
  visible_devices: "all"
  driver_capabilities: "compute,utility"

amd:
  visible_devices: "all"
  enable_pre_vega: "1"

# SLURM configuration (basic defaults)
slurm:
  # Login/head node configuration
  login_node:
    hostname: "slurm-login"
    address: "localhost"
    port: 22
    username: "madengine"
    ssh_key_path: "~/.ssh/id_rsa"

  # Cluster identification
  cluster_name: "madengine-cluster"

  # Basic partition configuration
  partitions:
    - name: "gpu"
      max_time: "24:00:00"
      max_nodes: 8
      default_gpu_count: 1
      gpu_types: ["gpu"]
      memory_per_node: "64G"
      gpu_vendor: "AMD"

  # Basic modules
  modules:
    - "python/3.9"
    - "gcc/11.2.0"

  # Basic environment
  environment:
    OMP_NUM_THREADS: "1"

  # GPU mapping
  gpu_mapping:
    AMD:
      gres_name: "gpu"
      constraint: ""
      memory_per_gpu: "16G"
    NVIDIA:
      gres_name: "gpu"
      constraint: ""
      memory_per_gpu: "16G"

  # Execution defaults
  execution:
    max_concurrent_jobs: 4
    job_array_strategy: true
    default_timeout: 3600
    retry_failed_jobs: false
    max_retries: 1
